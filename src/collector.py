import requests
from bs4 import BeautifulSoup as BS
from fake_useragent import UserAgent
from loguru import logger



@logger.catch
def get_games():
    headers = {
        'Referer': 'https://store.steampowered.com/search/?force_infinite=1&maxprice=free&specials=1&ndl=1',
        'User-Agent': UserAgent(browsers="chrome", platforms="desktop").random,
        'Accept': '*/*',
    }

    # –í –∑–∞–ø—Ä–æ—Å–µ —É–∂–µ –µ—Å—Ç—å –ø–∞—Ä–∞–º–µ—Ç—Ä—ã —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏
    response = requests.get('https://store.steampowered.com/search/results?force_infinite=1&maxprice=free&specials=1&ndl=1&snr=1_7_7_230_7', headers=headers)
    soup = BS(response.text, "lxml")
    logger.debug(f"–û—Ç–≤–µ—Ç {response.status_code}")

    try:
        all_games = soup.find("div", id="search_resultsRows")
        all_games = all_games.find_all("a", recursive=False)
    except Exception as e:
        logger.info(f"–°–µ–π—á–∞—Å –Ω–µ—Ç—É –±–µ—Å–ø–ª–∞—Ç–Ω—ã—Ö –∏–≥—Ä! {e}")
        return

    logger.info(f"–ü–æ–ª—É—á–µ–Ω–æ {len(all_games)} –∏–≥—Ä –∏–∑ –æ—Ç–≤–µ—Ç–∞.")
    if not all_games:
        logger.warning("–°–ø–∏—Å–æ–∫ –∏–≥—Ä –ø—É—Å—Ç.")
        return 

    games_list = dict()
    for game in all_games:
        app_id = game["data-ds-appid"]
        logger.debug(f"ID –∏–≥—Ä—ã: {app_id}")
        title = game.find("span", class_="title").text
        logger.debug(f"–ù–∞–∑–≤–∞–Ω–∏–µ {title}")
        discounted_price_tag = game.find("div", class_="discount_final_price")
        discounted_price = discounted_price_tag.text.strip() if discounted_price_tag else 0
        currency_symbol = discounted_price[-1]
        logger.debug(f"–°–∏–º–≤–æ–ª –≤–∞–ª—é—Ç—ã: {currency_symbol}")
        discounted_price = str(discounted_price).replace(",", ".")[:-1]  # –£–±–∏—Ä–∞–µ–º –∑–Ω–∞–∫ –≤–∞–ª—é—Ç—ã, –º–µ–Ω—è–µ–º –∑–∞–ø—è—Ç—É—é –Ω–∞ —Ç–æ—á–∫—É –¥–ª—è –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è –≤ float
        discounted_price = float(discounted_price)
        logger.debug(f"–¶–µ–Ω–∞: {discounted_price}{currency_symbol}")
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —Ü–µ–Ω–∞ –Ω—É–ª–µ–≤–∞—è. –ù–µ –∑–Ω–∞—é –ø–æ—á–µ–º—É, –Ω–æ –∏–Ω–æ–≥–¥–∞ –∏–≥—Ä–∞ –º–æ–∂–µ—Ç –±—ã—Ç—å –Ω–µ —Å–æ 100% —Å–∫–∏–¥–∫–æ–π, —Ö–æ—Ç—è —Ñ–∏–ª—å—Ç—Ä –Ω–µ –¥–æ–ª–∂–µ–Ω –ø–æ–∫–∞–∑—ã–≤–∞—Ç—å —Ç–∞–∫–∏–µ –∏–≥—Ä—ã
        # –ú–Ω–µ –∫–∞–∂–µ—Ç—Å—è, —á—Ç–æ —ç—Ç–æ —è –∑–∞–±—ã–ª —É–±—Ä–∞—Ç—å –ø–ª—Å–ª–µ –∏—Å–ø—Ä–≤–ª–µ–Ω–∏—è –∫–∞–∫–æ–π —Ç–æ —á–∞—Å—Ç–∏ –∫–æ–¥–∞.
        if discounted_price != 0:
            logger.debug(f"–ù–µ –±–µ—Å–ø–ª–∞—Ç–Ω–∞, —Ü–µ–Ω–∞: {discounted_price}")
            continue

        url = game.get("href")
        logger.debug(f"URL: {url}")
        image = game.find("div", class_="search_capsule").find("img").get("src")
        logger.debug(f"–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ: {image}")
        original_price = game.find("div", class_="discount_original_price")
        logger.debug(f"–¶–µ–Ω–∞ –±–µ–∑ —Å–∫–∏–¥–∫–∏: {original_price.text.strip() if original_price else '–ù–µ—Ç –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–π —Ü–µ–Ω—ã'}")

        res = requests.get(url)
        soup = BS(res.text, "lxml")
        logger.debug(f"–ü–æ–ª—É—á–µ–Ω HTML-–∫–æ–¥ —Å—Ç—Ä–∞–Ω–∏—Ü—ã, –¥–ª—è –¥–µ—Ç–∞–ª—å–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏: {url}.")

        desc_tag = soup.find("div", class_="game_description_snippet")
        description = desc_tag.text.strip() if desc_tag else "–û–ø–∏—Å–∞–Ω–∏–µ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ"
        logger.debug(f"–û–ø–∏—Å–∞–Ω–∏–µ: {description}")

        mini_div_info = soup.find("div", class_="glance_ctn_responsive_left")

        user_reviews = mini_div_info.find("div", id="userReviews")
        logger.debug("–ü–æ–ª—É—á–µ–Ω div id=userReviews")
        recent_reviews_row = user_reviews.find("div", class_="summary column")
        logger.debug("–ü–æ–ª—É—á–µ–Ω div class=summary column")
        review_summary = recent_reviews_row.find_all("span")[0].text.strip()
        logger.debug(f"–û–±—â–µ–µ –≤–ø–µ—á–∞—Ç–ª–µ–Ω–∏–µ {review_summary}")
        try:
            review_count_text = recent_reviews_row.find_all("span")[1].text.strip()
            review_count = int(review_count_text.strip("()").replace(",", "").replace(" ", ""))
        except Exception as e:
            review_count = review_count_text
            logger.debug(f" –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –æ–±–∑–æ—Ä–æ–≤ –¥–ª—è —Ä–∞—Å—á–µ—Ç–∞ —Ä–µ–π—Ç–∏–Ω–≥–∞: –û—à–∏–±–∫–∞: {e}")

        logger.debug(f"–ù–µ–¥–∞–≤–Ω–∏–µ –æ—Ç–∑—ã–≤—ã: {review_count} –æ—Ç–∑—ã–≤–æ–≤, –æ–±—â–µ–µ –≤–ø–µ—á–∞—Ç–ª–µ–Ω–∏–µ: {review_summary}")

        all_reviews = user_reviews.find_all("a", class_="user_reviews_summary_row")[-1]["data-tooltip-html"]
        logger.debug(f"–í—Å–µ –æ—Ç–∑—ã–≤—ã {all_reviews}")

        release_date_tag = mini_div_info.find("div", class_="date")
        release_date = release_date_tag.text.strip() if release_date_tag else "–î–∞—Ç–∞ –≤—ã–ø—É—Å–∫–∞ –Ω–µ —É–∫–∞–∑–∞–Ω–∞"
        logger.debug(f"–î–∞—Ç–∞ –≤—ã–ø—É—Å–∫–∞: {release_date}")

        # –ó–¥–µ—Å—å —è –Ω–µ —É–≤–µ—Ä–µ–Ω, –º–æ–∂–µ—Ç –±—ã—Ç—å —á—Ç–æ, –≤ —Å—Ç–∏–º–µ –Ω–µ —É–∫–∞–∑—ã–≤–∞—Ç—å—Å—è —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫ –∏ –∏–∑–¥–∞—Ç–µ–ª—å?.
        developer_url = mini_div_info.find("div", id="developers_list").find("a")["href"]
        developer_name_tag = mini_div_info.find("div", id="developers_list").find("a")
        developer_name = developer_name_tag.text.strip() if developer_name_tag else "–†–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫ –Ω–µ —É–∫–∞–∑–∞–Ω"
        developer = {
            "name": developer_name,
            "url": developer_url
        }
        logger.debug(f"–†–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫ {developer_name} ({developer_url})")

        publisher_tag = mini_div_info.find_all("div", class_="dev_row")[-1]
        if publisher_tag:
            publisher_link = publisher_tag.find("a")
            publisher_name = publisher_link.text.strip() if publisher_link else "–ò–∑–¥–∞—Ç–µ–ª—å –Ω–µ —É–∫–∞–∑–∞–Ω"
            publisher_url = publisher_link["href"] if publisher_link and publisher_link.has_attr("href") else "–ò–∑–¥–∞—Ç–µ–ª—å –Ω–µ —É–∫–∞–∑–∞–Ω"
        else:
            publisher_name = "–ò–∑–¥–∞—Ç–µ–ª—å –Ω–µ —É–∫–∞–∑–∞–Ω"
            publisher_url = "–ò–∑–¥–∞—Ç–µ–ª—å –Ω–µ —É–∫–∞–∑–∞–Ω"

        publisher = {
            "name": publisher_name,
            "url": publisher_url
        }
        logger.debug(f"–ò–∑–¥–∞—Ç–µ–ª—å {publisher_name} ({publisher_url})")

        dlc = soup.find("div", class_="game_area_bubble game_area_dlc_bubble")
        if dlc:
            dlc_url = dlc.find("a")["href"]
            dlc_name_tag = dlc.find("a")
            dlc_name = dlc_name_tag.text.strip()
            dlc = {
                "name": dlc_name,
                "url": dlc_url
            }
            logger.debug(f"DLC {dlc_name} ({dlc_url})")
        else:
            dlc = None
        
        games_list[app_id] = {
            "name": title,
            "url": url,
            "image": image,
            "description": description,
            "discounted_price": discounted_price,
            "currency_symbol": currency_symbol,
            "original_price": original_price.text.strip() if original_price else "–ù–µ—Ç –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–π —Ü–µ–Ω—ã",
            "developer": developer,
            "publisher": publisher,
            "release_date": release_date,
            "recent_reviews": review_count,
            "all_reviews": all_reviews,
            "dlc": dlc,
            "status": "new"
        }

        logger.info(f"–û–±—Ä–∞–±–æ—Ç–∫–∞ {title} –∑–∞–≤–µ—Ä—à–µ–Ω–∞.")

    logger.info("üëè –í—Å–µ –∏–≥—Ä—ã —É—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ.")
    return games_list


if __name__ == "__main__":
    games_list = get_games()
    print(games_list)